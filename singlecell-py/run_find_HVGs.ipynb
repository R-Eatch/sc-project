{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c60dfd-9e24-4941-9776-81fc82d6e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from venn import venn\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Configuration ---\n",
    "N_TOP_GENES = 5000\n",
    "RE_FIND_TOP_GENES = True # Always re-find HVGs based on subsetted data per stage\n",
    "\n",
    "# Define base file paths and sample names\n",
    "BASE_DATA_DIR = \"../../\" # Adjust if needed\n",
    "SAMPLE_INFO = {\n",
    "    \"R-MG\": os.path.join(BASE_DATA_DIR, \"R-MG/1.subset/R-MG_cleaned.h5ad\"),\n",
    "    \"R-AG\": os.path.join(BASE_DATA_DIR, \"R-AG/1.subset/R-AG_cleaned.h5ad\"),\n",
    "    \"S-MG\": os.path.join(BASE_DATA_DIR, \"S-MG/1.subset/S-MG_cleaned.h5ad\"),\n",
    "    \"S-AG\": os.path.join(BASE_DATA_DIR, \"S-AG/1.subset/S-AG_cleaned.h5ad\"),\n",
    "    \"M-MG\": os.path.join(BASE_DATA_DIR, \"M-MG/1.subset/M-MG_cleaned.h5ad\"),\n",
    "    \"R-CG\": os.path.join(BASE_DATA_DIR, \"R-CG/1.subset/R-CG_cleaned.h5ad\")\n",
    "}\n",
    "# 3. 需要提取数据的目标列名（交集名称）\n",
    "TARGET_INTERSECTIONS = [\n",
    "    'M-MG & R-MG & S-MG',                     # 三种 MG 的交集\n",
    "    'M-MG & R-AG & R-CG & R-MG & S-AG & S-MG', # 六个样本的总交集 (请确认此列名与你CSV中的完全一致)\n",
    "    'R-AG & S-AG'                              # 两种 AG 的交集\n",
    "]\n",
    "ALL_SAMPLE_NAMES = list(SAMPLE_INFO.keys())\n",
    "MG_SAMPLE_NAMES = [\"R-MG\", \"S-MG\", \"M-MG\"] # Define MG samples for specific analysis\n",
    "USE_NOVEL_GENE = False\n",
    "# Novel Gene File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d08aa5-725d-4405-95c9-471c174b869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use absolute path or ensure relative path is correct from script execution location\n",
    "NOVEL_GENE_FILE = \"/data02/sunxuebo/project/scrnaseq/no-mammal/mammalnewgene/mammalian_new_genes_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95003a-f5a7-4fa4-af7a-0b18ea8f30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if novel gene file exists\n",
    "if not os.path.exists(NOVEL_GENE_FILE):\n",
    "     warnings.warn(f\"Novel gene file not found at: {NOVEL_GENE_FILE}. Skipping novel gene analysis.\")\n",
    "     NOVEL_GENE_FILE = None # Set to None if not found\n",
    "\n",
    "# Output directory for stage-specific results\n",
    "OUTPUT_BASE_DIR = \"stage_specific_hvg_analysis\"\n",
    "os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_unique_stages(sample_info_dict):\n",
    "    \"\"\"Reads all AnnData objects to find unique stages.\"\"\"\n",
    "    unique_stages = set()\n",
    "    print(\"Identifying unique stages across all samples...\")\n",
    "    for sample, path in sample_info_dict.items():\n",
    "        try:\n",
    "            if os.path.exists(path):\n",
    "                adata = sc.read(path, cache=True)\n",
    "                if 'stage' in adata.obs.columns:\n",
    "                    unique_stages.update(adata.obs['stage'].unique())\n",
    "                else:\n",
    "                    print(f\"Warning: 'stage' column not found in {sample}\")\n",
    "            else:\n",
    "                print(f\"Warning: File not found for {sample} at {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {sample} from {path}: {e}\")\n",
    "    print(f\"Found stages: {list(unique_stages)}\")\n",
    "    return list(unique_stages)\n",
    "\n",
    "def load_hvgs_for_stage(sample_name, file_path, stage, n_top_genes):\n",
    "    \"\"\"Loads data, subsets by stage, finds HVGs.\"\"\"\n",
    "    print(f\"  Processing {sample_name} for stage '{stage}'...\")\n",
    "    try:\n",
    "        adata_full = sc.read(file_path, cache=True)\n",
    "\n",
    "        if 'stage' not in adata_full.obs.columns:\n",
    "            print(f\"  Warning: 'stage' column missing in {sample_name}. Skipping stage subsetting.\")\n",
    "            adata_stage = adata_full # Process full data if no stage info\n",
    "        else:\n",
    "             # Check if stage exists in this sample\n",
    "            if stage not in adata_full.obs['stage'].unique():\n",
    "                 print(f\"  Stage '{stage}' not found in {sample_name}. Skipping sample for this stage.\")\n",
    "                 return None, False # Return None HVGs, Indicate invalid\n",
    "\n",
    "            adata_stage = adata_full[adata_full.obs['stage'] == stage].copy()\n",
    "\n",
    "        if adata_stage.n_obs == 0:\n",
    "            print(f\"  No cells found for stage '{stage}' in {sample_name}. Skipping.\")\n",
    "            return None, False # Return None HVGs, Indicate invalid\n",
    "\n",
    "        print(f\"  Found {adata_stage.n_obs} cells for stage '{stage}' in {sample_name}.\")\n",
    "\n",
    "        # Normalize and log-transform (necessary for HVG finding)\n",
    "        adata_stage.X=adata_stage.layers['counts']\n",
    "        sc.pp.normalize_total(adata_stage)\n",
    "        sc.pp.log1p(adata_stage)\n",
    "\n",
    "        # Find HVGs on the stage-specific subset\n",
    "        sc.pp.highly_variable_genes(adata_stage, n_top_genes=n_top_genes) # Using seurat_v3 is common\n",
    "        hvgs = adata_stage.var[adata_stage.var['highly_variable']].index.tolist()\n",
    "        print(f\"  {sample_name} (Stage {stage}): {len(hvgs)} HVGs found.\")\n",
    "        return set(hvgs), True # Return HVG set, Indicate valid\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Error: File not found for {sample_name} at {file_path}\")\n",
    "        return None, False\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {sample_name} for stage '{stage}': {e}\")\n",
    "        return None, False\n",
    "\n",
    "def calculate_intersections_for_plot(hvgs_dict, sample_names, mg_sample_names):\n",
    "    \"\"\"Calculates specific intersections needed for the UpSet-style plot.\"\"\"\n",
    "    intersections = {}\n",
    "    valid_sample_names = list(hvgs_dict.keys()) # Samples actually present in this stage\n",
    "\n",
    "    # 1. All pairwise intersections among valid samples\n",
    "    for comb in combinations(valid_sample_names, 2):\n",
    "        intersect_set = hvgs_dict[comb[0]] & hvgs_dict[comb[1]]\n",
    "        intersections[comb] = len(intersect_set)\n",
    "\n",
    "    # 2. Three MG sample intersection (if all are present)\n",
    "    valid_mg_samples = [s for s in mg_sample_names if s in valid_sample_names]\n",
    "    if len(valid_mg_samples) == 3:\n",
    "        mg_comb = tuple(sorted(valid_mg_samples)) # Ensure consistent order\n",
    "        intersect_set = set.intersection(*(hvgs_dict[sample] for sample in mg_comb))\n",
    "        intersections[mg_comb] = len(intersect_set)\n",
    "    elif len(valid_mg_samples) > 0 :\n",
    "         print(f\"  Note: Not all 3 MG samples ({mg_sample_names}) present/valid in this stage. Skipping 3-way MG intersection plot point.\")\n",
    "\n",
    "    # 3. Intersection of all valid samples for this stage (if more than 1)\n",
    "    if len(valid_sample_names) > 1:\n",
    "         all_comb = tuple(sorted(valid_sample_names))\n",
    "         intersect_set = set.intersection(*(hvgs_dict[sample] for sample in all_comb))\n",
    "         intersections[all_comb] = len(intersect_set)\n",
    "\n",
    "    # Also include single sets for context in the plot if needed (optional, original plot didn't show singles)\n",
    "    # for sample in valid_sample_names:\n",
    "    #     intersections[(sample,)] = len(hvgs_dict[sample])\n",
    "\n",
    "    print(f\"  Calculated {len(intersections)} intersection counts for plotting.\")\n",
    "    return intersections\n",
    "\n",
    "def plot_upset_style(intersections, all_possible_sample_names, output_dir, filename_prefix=\"\"):\n",
    "    \"\"\"Plots the UpSet-style visualization for calculated intersections.\"\"\"\n",
    "    if not intersections:\n",
    "        print(\"  No intersections to plot.\")\n",
    "        return\n",
    "\n",
    "    # Prepare data - sort by count descending\n",
    "    combinations_list = list(intersections.keys())\n",
    "    counts = list(intersections.values())\n",
    "    # Filter out zero counts before sorting (important!)\n",
    "    non_zero_indices = [i for i, count in enumerate(counts) if count > 0]\n",
    "    if not non_zero_indices:\n",
    "        print(\"  No non-zero intersections to plot.\")\n",
    "        return\n",
    "\n",
    "    combinations_list = [combinations_list[i] for i in non_zero_indices]\n",
    "    counts = [counts[i] for i in non_zero_indices]\n",
    "\n",
    "    sorted_indices = sorted(range(len(counts)), key=lambda i: counts[i], reverse=True)\n",
    "    combinations_sorted = [combinations_list[i] for i in sorted_indices]\n",
    "    counts_sorted = [counts[i] for i in sorted_indices]\n",
    "\n",
    "    # Determine the samples actually involved in the plotted intersections\n",
    "    plotted_samples = sorted(list(set(s for comb in combinations_sorted for s in comb)))\n",
    "    # Use all_possible_sample_names to maintain consistent y-axis order if desired\n",
    "    # y_axis_samples = all_possible_sample_names\n",
    "    y_axis_samples = plotted_samples # Or just plot the relevant ones\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(max(15, len(combinations_sorted) * 0.8), 8)) # Adjust size dynamically\n",
    "    grid = fig.add_gridspec(nrows=2, ncols=1, height_ratios=[3, 1], hspace=0.05)\n",
    "\n",
    "    # Bar chart (top)\n",
    "    ax_bar = fig.add_subplot(grid[0, 0])\n",
    "    bar_positions = np.arange(len(combinations_sorted))\n",
    "    bar_width = 0.6\n",
    "    cmap = plt.cm.get_cmap(\"viridis\", len(combinations_sorted))\n",
    "    colors = [cmap(i) for i in range(len(combinations_sorted))]\n",
    "    bars = ax_bar.bar(bar_positions, counts_sorted, width=bar_width, color=colors)\n",
    "    ax_bar.set_xticks(bar_positions)\n",
    "    ax_bar.set_xticklabels([]) # Hide x-tick labels\n",
    "    ax_bar.set_ylabel(\"Number of Shared HVGs\")\n",
    "    ax_bar.set_title(f\"{filename_prefix}Intersection of HVGs ({len(y_axis_samples)} Samples)\", fontsize=14)\n",
    "    ax_bar.set_xlim(-0.5, len(combinations_sorted) - 0.5)\n",
    "    ax_bar.tick_params(axis='x', length=0) # Hide x-tick marks\n",
    "\n",
    "    for bar, count in zip(bars, counts_sorted):\n",
    "        ax_bar.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(5, 0.01 * max(counts_sorted)), # Adjust text offset\n",
    "                    str(count), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Intersection matrix (bottom)\n",
    "    ax_matrix = fig.add_subplot(grid[1, 0], sharex=ax_bar) # Share x-axis\n",
    "\n",
    "    # Set alternating background colors for rows\n",
    "    for i in range(len(y_axis_samples)):\n",
    "        ax_matrix.axhspan(i - 0.5, i + 0.5, color='lightgrey' if i % 2 == 0 else 'white', alpha=0.6, zorder=0)\n",
    "\n",
    "    for i, comb in enumerate(combinations_sorted):\n",
    "        present_indices = [y_axis_samples.index(s) for s in comb if s in y_axis_samples]\n",
    "        if not present_indices: continue\n",
    "\n",
    "        # Plot dots\n",
    "        ax_matrix.scatter([i] * len(present_indices), present_indices, color='black', s=50, zorder=2)\n",
    "        # Plot connecting lines\n",
    "        if len(present_indices) > 1:\n",
    "            ax_matrix.plot([i, i], [min(present_indices), max(present_indices)], color='black', lw=1.5, zorder=1)\n",
    "\n",
    "    ax_matrix.set_xticks(bar_positions)\n",
    "    # Set combination labels if needed (can get crowded)\n",
    "    # comb_labels = [' & '.join(map(str, c)) for c in combinations_sorted]\n",
    "    # ax_matrix.set_xticklabels(comb_labels, rotation=90, ha='center', fontsize=8)\n",
    "    ax_matrix.set_xticklabels([]) # Usually better to hide them and rely on the dots\n",
    "\n",
    "    ax_matrix.set_yticks(np.arange(len(y_axis_samples)))\n",
    "    ax_matrix.set_yticklabels(y_axis_samples)\n",
    "    ax_matrix.set_xlim(-0.5, len(combinations_sorted) - 0.5)\n",
    "    ax_matrix.set_ylim(-0.5, len(y_axis_samples) - 0.5)\n",
    "    ax_matrix.invert_yaxis() # Place top sample at the top\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97]) # Adjust layout slightly for title\n",
    "    png_path = os.path.join(output_dir, f\"{filename_prefix}HVGs_intersections_upset.png\")\n",
    "    pdf_path = os.path.join(output_dir, f\"{filename_prefix}HVGs_intersections_upset.pdf\")\n",
    "    plt.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(pdf_path, dpi=400, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"  Upset-style plot saved to {png_path} and {pdf_path}\")\n",
    "\n",
    "def calculate_and_export_all_intersections(hvgs_dict, output_dir, filename_prefix=\"\"):\n",
    "    \"\"\"Calculates all pairwise and higher-order intersections and saves to CSV.\"\"\"\n",
    "    intersections_genes = {}\n",
    "    valid_sample_names = list(hvgs_dict.keys())\n",
    "\n",
    "    print(\"  Calculating all intersections...\")\n",
    "    # Calculate intersections for all combination sizes (2, 3, ..., N)\n",
    "    for k in range(2, len(valid_sample_names) + 1):\n",
    "        for comb in combinations(valid_sample_names, k):\n",
    "            intersect_set = set.intersection(*(hvgs_dict[sample] for sample in comb))\n",
    "            if intersect_set: # Only store non-empty intersections\n",
    "                intersection_name = \" & \".join(sorted(list(comb)))\n",
    "                intersections_genes[intersection_name] = sorted(list(intersect_set))\n",
    "                print(f\"    {intersection_name}: {len(intersect_set)} genes\")\n",
    "\n",
    "    if not intersections_genes:\n",
    "        print(\"  No intersections found.\")\n",
    "        return None # Indicate no file was saved\n",
    "\n",
    "    # Export to CSV\n",
    "    # Pad lists to the same length for DataFrame creation\n",
    "    max_length = max(len(genes) for genes in intersections_genes.values()) if intersections_genes else 0\n",
    "    export_data = {name: genes + [\"\"] * (max_length - len(genes)) for name, genes in intersections_genes.items()}\n",
    "    df = pd.DataFrame(export_data)\n",
    "\n",
    "    # Sort columns alphabetically for consistency\n",
    "    df = df[sorted(df.columns)]\n",
    "\n",
    "    output_csv = os.path.join(output_dir, f\"{filename_prefix}HVGs_all_intersections.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"  All intersection gene lists saved to {output_csv}\")\n",
    "    return output_csv # Return the path to the saved file\n",
    "\n",
    "def calculate_and_export_unique_hvgs(hvgs_dict, output_dir, filename_prefix=\"\"):\n",
    "    \"\"\"Calculates unique HVGs for each sample and saves to CSV.\"\"\"\n",
    "    unique_hvgs_dict = {}\n",
    "    all_unique_data = []\n",
    "    valid_sample_names = list(hvgs_dict.keys())\n",
    "    print(\"  Calculating unique HVGs...\")\n",
    "\n",
    "    for i, name in enumerate(valid_sample_names):\n",
    "        other_sets = [hvgs_dict[valid_sample_names[j]] for j in range(len(valid_sample_names)) if j != i]\n",
    "        # Handle case where there are no 'other' sets (only one sample)\n",
    "        if other_sets:\n",
    "            union_of_others = set.union(*other_sets)\n",
    "            unique_hvgs = hvgs_dict[name] - union_of_others\n",
    "        else:\n",
    "            unique_hvgs = hvgs_dict[name] # If only one sample, all its HVGs are unique\n",
    "\n",
    "        unique_hvgs_dict[name] = unique_hvgs\n",
    "        print(f\"    Unique HVGs for {name}: {len(unique_hvgs)}\")\n",
    "        for hvg in sorted(list(unique_hvgs)):\n",
    "            all_unique_data.append([name, hvg])\n",
    "\n",
    "    if not all_unique_data:\n",
    "        print(\"  No unique HVGs found.\")\n",
    "        return None, None # Indicate no file was saved and return empty dict\n",
    "\n",
    "    df = pd.DataFrame(all_unique_data, columns=[\"Sample\", \"HVG\"])\n",
    "    output_csv = os.path.join(output_dir, f\"{filename_prefix}HVGs_unique.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"  Unique HVGs saved to {output_csv}\")\n",
    "    return output_csv, unique_hvgs_dict # Return path and the dictionary\n",
    "\n",
    "def perform_mg_specific_analysis(hvgs_dict, mg_sample_names, output_dir):\n",
    "    \"\"\"Performs Venn, Bar chart, and intersection saving specific to MG samples.\"\"\"\n",
    "    valid_mg_samples = [s for s in mg_sample_names if s in hvgs_dict]\n",
    "\n",
    "    if len(valid_mg_samples) < 2:\n",
    "        print(f\"  Skipping MG-specific analysis: Found {len(valid_mg_samples)}/{len(mg_sample_names)} MG samples valid for this stage.\")\n",
    "        return\n",
    "\n",
    "    print(f\"  Performing MG-specific analysis for: {valid_mg_samples}\")\n",
    "    mg_hvgs_dict = {s: hvgs_dict[s] for s in valid_mg_samples}\n",
    "\n",
    "    # 1. Venn Diagram (only works well for 2 or 3 sets)\n",
    "    if len(valid_mg_samples) in [2, 3]:\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            venn(mg_hvgs_dict)\n",
    "            plt.title(f\"Venn Diagram of MG HVGs ({' & '.join(valid_mg_samples)})\")\n",
    "            venn_png_path = os.path.join(output_dir, \"MG_HVGs_Venn.png\")\n",
    "            venn_pdf_path = os.path.join(output_dir, \"MG_HVGs_Venn.pdf\")\n",
    "            plt.savefig(venn_png_path, dpi=300, bbox_inches='tight')\n",
    "            plt.savefig(venn_pdf_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"    MG Venn diagram saved to {venn_png_path} and {venn_pdf_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Error generating Venn diagram: {e}\") # Venn lib can sometimes fail\n",
    "\n",
    "    # 2. Bar Chart of Pairwise and (if 3 samples) Triple Intersections\n",
    "    shared_counts = {}\n",
    "    shared_genes = {} # Store actual genes for saving later\n",
    "\n",
    "    # Pairwise\n",
    "    for s1, s2 in combinations(valid_mg_samples, 2):\n",
    "        shared = mg_hvgs_dict[s1] & mg_hvgs_dict[s2]\n",
    "        label = f\"{s1} & {s2}\"\n",
    "        shared_counts[label] = len(shared)\n",
    "        shared_genes[label] = shared\n",
    "        print(f\"      Shared {label}: {len(shared)}\")\n",
    "\n",
    "    # Triple (if 3 samples)\n",
    "    if len(valid_mg_samples) == 3:\n",
    "        shared_all = set.intersection(*mg_hvgs_dict.values())\n",
    "        label_all = f\"All ({' & '.join(valid_mg_samples)})\"\n",
    "        shared_counts[label_all] = len(shared_all)\n",
    "        shared_genes[label_all] = shared_all\n",
    "        print(f\"      Shared All 3 MG: {len(shared_all)}\")\n",
    "\n",
    "    if shared_counts:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        categories = list(shared_counts.keys())\n",
    "        values = list(shared_counts.values())\n",
    "        # Use distinct colors\n",
    "        colors = plt.cm.get_cmap('Pastel1', len(categories)).colors\n",
    "        plt.bar(categories, values, color=colors, width=0.5)\n",
    "        plt.xlabel(\"MG Sample Groups\", fontsize=12)\n",
    "        plt.ylabel(\"Number of Shared HVGs\", fontsize=12)\n",
    "        plt.title(\"Shared HVGs Among MG Samples\", fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        bar_png_path = os.path.join(output_dir, \"MG_HVGs_shared_barplot.png\")\n",
    "        bar_pdf_path = os.path.join(output_dir, \"MG_HVGs_shared_barplot.pdf\")\n",
    "        plt.savefig(bar_png_path, dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(bar_pdf_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"    MG shared HVGs bar plot saved to {bar_png_path} and {bar_pdf_path}\")\n",
    "\n",
    "        # 3. Save MG intersection genes to CSV\n",
    "        mg_intersect_data = []\n",
    "        for group, genes in shared_genes.items():\n",
    "            for gene in sorted(list(genes)):\n",
    "                 mg_intersect_data.append([group, gene])\n",
    "\n",
    "        if mg_intersect_data:\n",
    "             df_mg_intersect = pd.DataFrame(mg_intersect_data, columns=[\"Intersection Group\", \"Gene\"])\n",
    "             mg_csv_path = os.path.join(output_dir, \"MG_HVGs_intersections.csv\")\n",
    "             df_mg_intersect.to_csv(mg_csv_path, index=False)\n",
    "             print(f\"    MG intersection genes saved to {mg_csv_path}\")\n",
    "\n",
    "\n",
    "def intersect_with_novel_genes(hvg_sets_dict, novel_genes_set, set_type_name, output_dir, filename_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Intersects sets of HVGs (e.g., intersections, unique) with a set of novel genes.\n",
    "\n",
    "    Args:\n",
    "        hvg_sets_dict (dict): Dict where keys are group names (e.g., \"SampleA & SampleB\", \"SampleC Unique\")\n",
    "                              and values are sets or lists of gene names.\n",
    "        novel_genes_set (set): Set of novel gene names.\n",
    "        set_type_name (str): Type of HVG set (e.g., \"intersection\", \"unique\") for filename.\n",
    "        output_dir (str): Directory to save the results.\n",
    "        filename_prefix (str): Optional prefix for the output filename.\n",
    "    \"\"\"\n",
    "    if not novel_genes_set:\n",
    "        print(f\"  Skipping novel gene intersection for {set_type_name} sets: Novel gene list not available.\")\n",
    "        return\n",
    "\n",
    "    print(f\"  Intersecting {set_type_name} HVGs with novel genes...\")\n",
    "    novel_intersections = {}\n",
    "    for group_name, gene_set in hvg_sets_dict.items():\n",
    "        # Ensure we are working with a set\n",
    "        if isinstance(gene_set, list):\n",
    "            gene_set = set(gene_set)\n",
    "        elif not isinstance(gene_set, set):\n",
    "             print(f\"    Warning: Unexpected data type for {group_name}. Skipping.\")\n",
    "             continue\n",
    "\n",
    "        novel_found = list(gene_set.intersection(novel_genes_set))\n",
    "        if novel_found:\n",
    "            novel_intersections[group_name] = sorted(novel_found)\n",
    "            print(f\"    {group_name}: Found {len(novel_found)} novel genes.\")\n",
    "        # else:\n",
    "            # print(f\"    {group_name}: No novel genes found.\")\n",
    "\n",
    "\n",
    "    if not novel_intersections:\n",
    "        print(f\"  No novel genes found in any {set_type_name} set.\")\n",
    "        return\n",
    "\n",
    "    # Export to CSV\n",
    "    max_length = max(len(genes) for genes in novel_intersections.values()) if novel_intersections else 0\n",
    "    export_data = {name: genes + [\"\"] * (max_length - len(genes)) for name, genes in novel_intersections.items()}\n",
    "    df = pd.DataFrame(export_data)\n",
    "\n",
    "     # Sort columns alphabetically for consistency\n",
    "    df = df[sorted(df.columns)]\n",
    "\n",
    "    output_csv = os.path.join(output_dir, f\"{filename_prefix}HVGs_{set_type_name}_novel_gene_overlap.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"  Novel gene overlap for {set_type_name} sets saved to {output_csv}\")\n",
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "\n",
    "def main():\n",
    "    # 1. Load Novel Genes (once)\n",
    "    novel_genes_set = set()\n",
    "    if NOVEL_GENE_FILE and USE_NOVEL_GENE:\n",
    "        try:\n",
    "            novel_df = pd.read_csv(NOVEL_GENE_FILE)\n",
    "            # Assuming the column with relevant genes is 'mouse' - **ADJUST IF NEEDED**\n",
    "            if 'mouse' in novel_df.columns:\n",
    "                 novel_genes_set = set(novel_df[\"mouse\"].dropna().astype(str).tolist())\n",
    "                 print(f\"Loaded {len(novel_genes_set)} unique novel genes for comparison.\")\n",
    "            else:\n",
    "                 print(f\"Warning: Column 'mouse' not found in {NOVEL_GENE_FILE}. Cannot load novel genes.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading novel gene file {NOVEL_GENE_FILE}: {e}\")\n",
    "    else:\n",
    "         print(\"Novel gene file not specified or not found. Skipping novel gene analysis.\")\n",
    "\n",
    "\n",
    "    # 2. Identify Unique Stages\n",
    "    stages = get_unique_stages(SAMPLE_INFO)\n",
    "    if not stages:\n",
    "        print(\"No stages identified or error reading data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Process Each Stage\n",
    "    for stage in stages:\n",
    "        print(f\"\\n--- Processing Stage: {stage} ---\")\n",
    "        stage_output_dir = os.path.join(OUTPUT_BASE_DIR, str(stage))\n",
    "        os.makedirs(stage_output_dir, exist_ok=True)\n",
    "\n",
    "        # 3.1 Load HVGs for this stage\n",
    "        stage_hvgs_dict = {}\n",
    "        stage_valid_samples = []\n",
    "        for sample_name in ALL_SAMPLE_NAMES:\n",
    "            file_path = SAMPLE_INFO[sample_name]\n",
    "            hvgs, is_valid = load_hvgs_for_stage(sample_name, file_path, stage, N_TOP_GENES)\n",
    "            if is_valid:\n",
    "                stage_hvgs_dict[sample_name] = hvgs\n",
    "                stage_valid_samples.append(sample_name)\n",
    "\n",
    "        if len(stage_valid_samples) < 2:\n",
    "             print(f\"Stage '{stage}': Found {len(stage_valid_samples)} valid samples. Need at least 2 for comparative analysis. Skipping stage.\")\n",
    "             continue\n",
    "\n",
    "        print(f\"\\nStage '{stage}': Analysis based on valid samples: {stage_valid_samples}\")\n",
    "\n",
    "        # 3.2 Calculate Intersections for UpSet-style plot\n",
    "        intersections_for_plot = calculate_intersections_for_plot(stage_hvgs_dict, stage_valid_samples, MG_SAMPLE_NAMES)\n",
    "\n",
    "        # 3.3 Plot UpSet-style plot\n",
    "        plot_upset_style(intersections_for_plot, stage_valid_samples, stage_output_dir, filename_prefix=f\"Stage_{stage}_\")\n",
    "\n",
    "        # 3.4 Calculate and Export *All* Intersections (pairwise, triplets, etc.)\n",
    "        all_intersections_csv = calculate_and_export_all_intersections(stage_hvgs_dict, stage_output_dir, filename_prefix=f\"Stage_{stage}_\")\n",
    "\n",
    "        # 3.5 Calculate and Export Unique HVGs\n",
    "        unique_hvgs_csv, unique_hvgs_dict = calculate_and_export_unique_hvgs(stage_hvgs_dict, stage_output_dir, filename_prefix=f\"Stage_{stage}_\")\n",
    "\n",
    "        # 3.6 Perform MG-Specific Analysis (if applicable)\n",
    "        perform_mg_specific_analysis(stage_hvgs_dict, MG_SAMPLE_NAMES, stage_output_dir) # Output filenames inside function are relative to stage_output_dir\n",
    "\n",
    "        # 3.7 Intersect with Novel Genes (if available)\n",
    "        if novel_genes_set:\n",
    "            # Intersect ALL intersection sets with novel genes\n",
    "            if all_intersections_csv: # Check if the file was actually created\n",
    "                 try:\n",
    "                     # Read the saved intersection data back (or pass the dictionary directly if refactored)\n",
    "                      intersections_df_for_novel = pd.read_csv(all_intersections_csv)\n",
    "                      intersection_sets_for_novel = {col: set(intersections_df_for_novel[col].dropna().astype(str))\n",
    "                                                    for col in intersections_df_for_novel.columns}\n",
    "                      intersect_with_novel_genes(intersection_sets_for_novel, novel_genes_set, \"intersection\", stage_output_dir, filename_prefix=f\"Stage_{stage}_\")\n",
    "                 except Exception as e:\n",
    "                     print(f\"  Error processing intersections CSV for novel gene overlap: {e}\")\n",
    "\n",
    "\n",
    "            # Intersect UNIQUE gene sets with novel genes\n",
    "            if unique_hvgs_dict: # Check if unique HVGs were found\n",
    "                 intersect_with_novel_genes(unique_hvgs_dict, novel_genes_set, \"unique\", stage_output_dir, filename_prefix=f\"Stage_{stage}_\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Analysis Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppress excessive warnings from dependencies if desired\n",
    "    # warnings.filterwarnings('ignore')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed04eaf-af21-4b32-b14b-776516574e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 包含各个 stage 子目录的基础路径\n",
    "#    假设你的脚本和 'stage_specific_hvg_analysis' 目录在同一级\n",
    "#    或者提供绝对路径 '/path/to/your/stage_specific_hvg_analysis'\n",
    "BASE_OUTPUT_DIR = \"./stage_specific_hvg_analysis\"\n",
    "\n",
    "# 2. 需要处理的 stage 名称列表\n",
    "STAGES_TO_PROCESS = ['stage0', 'stage1', 'stage2', 'stage3', 'stage4', 'ALL']\n",
    "#    注意：'ALL' 可能是你对所有阶段合并分析的结果目录名，请根据实际情况修改\n",
    "\n",
    "# 4. 输出整合后的CSV文件名\n",
    "CONSOLIDATED_OUTPUT_FILE = \"consolidated_target_novel_genes.csv\"\n",
    "\n",
    "# --- 脚本执行 ---\n",
    "\n",
    "# 用于存储最终结果的列表，每个元素是一个包含 [stage, intersection, gene] 的列表\n",
    "consolidated_data = []\n",
    "\n",
    "print(\"开始处理各个 stage 的 novel gene intersection 文件...\")\n",
    "\n",
    "# 遍历每个指定的 stage\n",
    "for stage_name in STAGES_TO_PROCESS:\n",
    "    print(f\"\\n--- 正在处理 Stage: {stage_name} ---\")\n",
    "\n",
    "    # 构建当前 stage 的子目录路径\n",
    "    stage_dir = os.path.join(BASE_OUTPUT_DIR, stage_name)\n",
    "\n",
    "    # 构建目标 CSV 文件的完整路径\n",
    "    # 文件名格式根据你的描述是 'Stage_{stage_name}_HVGs_intersection_novel_gene_overlap.csv'\n",
    "    if USE_NOVEL_GENE:\n",
    "        csv_filename = f'Stage_{stage_name}_HVGs_intersection_novel_gene_overlap.csv'\n",
    "    else:\n",
    "        csv_filename = f'Stage_{stage_name}_HVGs_all_intersections.csv'\n",
    "    csv_filepath = os.path.join(stage_dir, csv_filename)\n",
    "\n",
    "    # 检查目标 CSV 文件是否存在\n",
    "    if not os.path.exists(csv_filepath):\n",
    "        warnings.warn(f\"文件未找到，跳过: {csv_filepath}\")\n",
    "        continue # 跳到下一个 stage\n",
    "\n",
    "    # 读取 CSV 文件\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath)\n",
    "        print(f\"  成功读取文件: {csv_filename}\")\n",
    "\n",
    "        # 遍历需要提取的目标交集列名\n",
    "        for intersection_col in TARGET_INTERSECTIONS:\n",
    "            # 检查目标列是否存在于当前 DataFrame 中\n",
    "            if intersection_col in df.columns:\n",
    "                print(f\"    找到目标列: '{intersection_col}'\")\n",
    "                # 提取该列的基因名\n",
    "                # 使用 .dropna() 去除因为列长不一致而填充的 NaN/空值\n",
    "                # 使用 .astype(str) 确保基因名是字符串\n",
    "                # 使用 .unique() 可选，如果原始文件可能有重复基因且你只想保留唯一值\n",
    "                genes_in_intersection = df[intersection_col].dropna().astype(str).tolist()\n",
    "\n",
    "                if genes_in_intersection:\n",
    "                    print(f\"      提取到 {len(genes_in_intersection)} 个基因.\")\n",
    "                    # 将每个基因添加到结果列表中\n",
    "                    for gene in genes_in_intersection:\n",
    "                        # 确保基因名不是空字符串（虽然dropna通常能处理，加一层保险）\n",
    "                        if gene.strip():\n",
    "                            consolidated_data.append([stage_name, intersection_col, gene.strip()])\n",
    "                else:\n",
    "                    print(f\"      列 '{intersection_col}' 中没有找到有效基因名。\")\n",
    "\n",
    "            else:\n",
    "                # 如果目标列不存在，发出警告\n",
    "                warnings.warn(f\"在文件 {csv_filename} 中未找到列: '{intersection_col}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # 处理读取文件时可能发生的其他错误\n",
    "        warnings.warn(f\"读取文件时发生错误 {csv_filepath}: {e}\")\n",
    "        continue # 跳到下一个 stage\n",
    "\n",
    "# 将收集到的数据转换为 DataFrame\n",
    "if consolidated_data:\n",
    "    consolidated_df = pd.DataFrame(consolidated_data, columns=['stage', 'intersection', 'gene'])\n",
    "    print(f\"\\n数据整合完成，共收集到 {len(consolidated_df)} 条记录。\")\n",
    "\n",
    "    # 保存 DataFrame 到 CSV 文件\n",
    "    try:\n",
    "        consolidated_df.to_csv(CONSOLIDATED_OUTPUT_FILE, index=False)\n",
    "        print(f\"结果已成功保存到: {CONSOLIDATED_OUTPUT_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存最终CSV文件时出错: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n未能收集到任何数据，未生成输出文件。请检查输入目录、文件名和列名是否正确。\")\n",
    "\n",
    "print(\"\\n脚本执行完毕。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 Scanpy",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
