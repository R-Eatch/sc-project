{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26632d6c-aae6-46cd-a075-d5e38306afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from venn import venn\n",
    "n_topgenes=5000\n",
    "re_find_topgenes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340717e4-6ccf-4f37-907c-bfa0a797dbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample: R-MG from ../../R-MG/1.subset/R-MG_cleaned.h5ad...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '..\\..\\R-MG\\1.subset\\R-MG_cleaned.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 129\u001b[0m\n\u001b[0;32m    126\u001b[0m     plot_combined(intersections, sample_names, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHVGs-for-all.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# 运行主函数\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 124\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file_paths, sample_names)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(file_paths, sample_names):\n\u001b[1;32m--> 124\u001b[0m     hvgs_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_hvgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     intersections \u001b[38;5;241m=\u001b[39m calculate_intersections(hvgs_dict, sample_names)\n\u001b[0;32m    126\u001b[0m     plot_combined(intersections, sample_names, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHVGs-for-all.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m, in \u001b[0;36mload_hvgs\u001b[1;34m(file_paths, sample_names)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(file_paths):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     adata \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     hvgs \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar[adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighly_variable\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# 提取 HVGs\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     hvgs_dict[sample_names[i]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(hvgs)  \u001b[38;5;66;03m# 将 HVGs 存储为集合\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py310\\lib\\site-packages\\legacy_api_wrap\\__init__.py:80\u001b[0m, in \u001b[0;36mlegacy_api.<locals>.wrapper.<locals>.fn_compatible\u001b[1;34m(*args_all, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_compatible\u001b[39m(\u001b[38;5;241m*\u001b[39margs_all: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_all) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_positional:\n\u001b[1;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs_all, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m     82\u001b[0m     args_pos: P\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m     83\u001b[0m     args_pos, args_rest \u001b[38;5;241m=\u001b[39m args_all[:n_positional], args_all[n_positional:]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py310\\lib\\site-packages\\scanpy\\readwrite.py:130\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m filename \u001b[38;5;241m=\u001b[39m Path(filename)  \u001b[38;5;66;03m# allow passing strings\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_valid_filename(filename):\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read(\n\u001b[0;32m    131\u001b[0m         filename,\n\u001b[0;32m    132\u001b[0m         backed\u001b[38;5;241m=\u001b[39mbacked,\n\u001b[0;32m    133\u001b[0m         sheet\u001b[38;5;241m=\u001b[39msheet,\n\u001b[0;32m    134\u001b[0m         ext\u001b[38;5;241m=\u001b[39mext,\n\u001b[0;32m    135\u001b[0m         delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m    136\u001b[0m         first_column_names\u001b[38;5;241m=\u001b[39mfirst_column_names,\n\u001b[0;32m    137\u001b[0m         backup_url\u001b[38;5;241m=\u001b[39mbackup_url,\n\u001b[0;32m    138\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m    139\u001b[0m         cache_compression\u001b[38;5;241m=\u001b[39mcache_compression,\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# generate filename and read to dict\u001b[39;00m\n\u001b[0;32m    143\u001b[0m filekey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(filename)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py310\\lib\\site-packages\\scanpy\\readwrite.py:766\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sheet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbacked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m         logg\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py310\\lib\\site-packages\\anndata\\_io\\h5ad.py:234\u001b[0m, in \u001b[0;36mread_h5ad\u001b[1;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently only `X` and `raw/X` can be read as sparse.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m rdasp \u001b[38;5;241m=\u001b[39m partial(\n\u001b[0;32m    231\u001b[0m     read_dense_as_sparse, sparse_format\u001b[38;5;241m=\u001b[39mas_sparse_fmt, axis_chunk\u001b[38;5;241m=\u001b[39mchunk_size\n\u001b[0;32m    232\u001b[0m )\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(func, elem_name: \u001b[38;5;28mstr\u001b[39m, elem, iospec):\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m iospec\u001b[38;5;241m.\u001b[39mencoding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manndata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py310\\lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py310\\lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '..\\..\\R-MG\\1.subset\\R-MG_cleaned.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义文件路径和样本名称\n",
    "file_paths = [\n",
    "    \"D:/111/R-MG_cleaned.h5ad\",  # R-MG\n",
    "    \"D:/111/R-AG_cleaned.h5ad\",  # R-AG\n",
    "    \"D:/111/S-MG_cleaned.h5ad\",  # S-MG\n",
    "    \"D:/111/S-AG_cleaned.h5ad\",  # S-AG\n",
    "    \"D:/111/M-MG_cleaned.h5ad\",  # M-MG\n",
    "    \"D:/111/R-CG_cleaned.h5ad\"   # R-CG\n",
    "]\n",
    "file_paths = [\n",
    "    \"../../R-MG/1.subset/R-MG_cleaned.h5ad\",  # R-MG\n",
    "    \"../../R-AG/1.subset/R-AG_cleaned.h5ad\",  # R-AG\n",
    "    \"../../S-MG/1.subset/S-MG_cleaned.h5ad\",  # S-MG\n",
    "    \"../../S-AG/1.subset/S-AG_cleaned.h5ad\",  # S-AG\n",
    "    \"../../M-MG/1.subset/M-MG_cleaned.h5ad\",  # M-MG\n",
    "    \"../../R-CG/1.subset/R-CG_cleaned.h5ad\"   # R-CG\n",
    "]\n",
    "sample_names = [\"R-MG\", \"R-AG\", \"S-MG\", \"S-AG\", \"M-MG\", \"R-CG\"]\n",
    "\n",
    "# Step 1: 读取数据并提取 HVGs\n",
    "def load_hvgs(file_paths, sample_names):\n",
    "    hvgs_dict = {}\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        print(f\"Loading sample: {sample_names[i]} from {file_path}...\")\n",
    "        adata = sc.read(file_path)\n",
    "        if re_find_topgenes:\n",
    "            adata.X=adata.layers['counts']\n",
    "            sc.pp.normalize_total(adata)\n",
    "            sc.pp.log1p(adata)\n",
    "            sc.pp.highly_variable_genes(adata, n_top_genes=n_topgenes)\n",
    "            print(f're find hvgs: {n_topgenes}')\n",
    "        hvgs = adata.var[adata.var['highly_variable']].index.tolist()  # 提取 HVGs\n",
    "        hvgs_dict[sample_names[i]] = set(hvgs)  # 将 HVGs 存储为集合\n",
    "        print(f\"Sample {sample_names[i]}: {len(hvgs)} HVGs found.\\n\")\n",
    "    return hvgs_dict\n",
    "\n",
    "# Step 2: 计算交集数据\n",
    "def calculate_intersections(hvgs_dict, sample_names):\n",
    "    intersections = {}\n",
    "    selected_combinations = []  # 存储感兴趣的组合\n",
    "\n",
    "    # 两两交集\n",
    "    for comb in combinations(sample_names, 2):\n",
    "        selected_combinations.append(comb)\n",
    "\n",
    "    # 三 MG 样本交集\n",
    "    mg_samples = [\"R-MG\", \"S-MG\", \"M-MG\"]\n",
    "    selected_combinations.append(tuple(mg_samples))\n",
    "\n",
    "    # 所有六个样本的交集\n",
    "    selected_combinations.append(tuple(sample_names))\n",
    "\n",
    "    # 计算感兴趣的交集\n",
    "    for comb in selected_combinations:\n",
    "        intersect_set = set.intersection(*(hvgs_dict[sample] for sample in comb))\n",
    "        intersections[comb] = len(intersect_set)\n",
    "\n",
    "    return intersections\n",
    "\n",
    "# Step 3: 绘制拼接图像\n",
    "def plot_combined(intersections, sample_names, save_path=\"combined_plot.png\"):\n",
    "    # 准备数据\n",
    "    combinations = list(intersections.keys())\n",
    "    counts = list(intersections.values())\n",
    "    sorted_indices = sorted(range(len(counts)), key=lambda i: counts[i], reverse=True)\n",
    "    combinations = [combinations[i] for i in sorted_indices]\n",
    "    counts = [counts[i] for i in sorted_indices]\n",
    "\n",
    "    # 创建图像布局\n",
    "    fig = plt.figure(figsize=(20, 10))  # 增加宽度以拉长间距\n",
    "    grid = fig.add_gridspec(nrows=2, ncols=1, height_ratios=[2, 1], hspace=0.05)\n",
    "\n",
    "    # 上方柱状图\n",
    "    ax_bar = fig.add_subplot(grid[0, 0])\n",
    "    bar_positions = range(len(combinations))\n",
    "    bar_width = 0.6\n",
    "\n",
    "    # 使用 viridis 配色\n",
    "    cmap = plt.cm.get_cmap(\"viridis\", len(combinations))\n",
    "    colors = [cmap(i) for i in range(len(combinations))]\n",
    "\n",
    "    bars = ax_bar.bar(bar_positions, counts, width=bar_width, color=colors)  # 使用颜色方案\n",
    "    ax_bar.set_xticks(bar_positions)\n",
    "    ax_bar.set_xticklabels([])\n",
    "    ax_bar.set_ylabel(\"Number of HVGs\")\n",
    "    ax_bar.set_title(\"Intersection of HVGs Across Glandular Samples\", fontsize=16)\n",
    "    ax_bar.set_xlim(-0.5, len(combinations) - 0.5)  # 去掉左右空白\n",
    "\n",
    "    # 在柱子上标注基因数量\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax_bar.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5,\n",
    "                    str(count), ha='center', fontsize=10)\n",
    "\n",
    "    # 下方交集点线图\n",
    "    ax_upset = fig.add_subplot(grid[1, 0])\n",
    "\n",
    "    # 设置背景颜色交替\n",
    "    for i in range(len(sample_names)):\n",
    "        ax_upset.axhspan(i - 0.5, i + 0.5, color='lightgrey' if i % 2 == 0 else 'white', alpha=0.5)\n",
    "\n",
    "    for i, comb in enumerate(combinations):\n",
    "        for j, sample in enumerate(sample_names):\n",
    "            if sample in comb:\n",
    "                ax_upset.scatter(i, j, color='black', s=50)\n",
    "        if len(comb) > 1:\n",
    "            indices = [sample_names.index(sample) for sample in comb]\n",
    "            ax_upset.plot([i, i], [min(indices), max(indices)], color='black', lw=1)\n",
    "\n",
    "    ax_upset.set_xticks(bar_positions)  # 与柱状图共享 X 轴间距\n",
    "    ax_upset.set_xticklabels([])\n",
    "    ax_upset.set_yticks(range(len(sample_names)))\n",
    "    ax_upset.set_yticklabels(sample_names)\n",
    "    ax_upset.set_xlim(-0.5, len(combinations) - 0.5)  # 去掉左右空白\n",
    "    ax_upset.set_ylim(-0.5, len(sample_names) - 0.5)\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(\"HVGs-for-all.pdf\", dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Combined plot saved as {save_path}\")\n",
    "\n",
    "# 主函数\n",
    "def main(file_paths, sample_names):\n",
    "    hvgs_dict = load_hvgs(file_paths, sample_names)\n",
    "    intersections = calculate_intersections(hvgs_dict, sample_names)\n",
    "    plot_combined(intersections, sample_names, save_path=\"HVGs-for-all.png\")\n",
    "\n",
    "# 运行主函数\n",
    "main(file_paths, sample_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b228a-e023-4cfd-a749-7fbd2ec127a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义文件路径和样本名称\n",
    "file_paths = [\n",
    "    \"../../R-MG/1.subset/R-MG_cleaned.h5ad\",  # R-MG\n",
    "    #\"../../R-AG/1.subset/R-AG_cleaned.h5ad\",  # R-AG\n",
    "    \"../../S-MG/1.subset/S-MG_cleaned.h5ad\",  # S-MG\n",
    "    #\"../../S-AG/1.subset/S-AG_cleaned.h5ad\",  # S-AG\n",
    "    \"../../M-MG/1.subset/M-MG_cleaned.h5ad\",  # M-MG\n",
    "   # \"../../R-CG/1.subset/R-CG_cleaned.h5ad\"   # R-CG\n",
    "]\n",
    "sample_names = [\"R-MG\", \"S-MG\", \"M-MG\"]\n",
    "\n",
    "# Step 2: 计算任意两组的共有 HVGs 数量\n",
    "def calculate_shared_hvgs(hvgs_dict, sample1, sample2):\n",
    "    shared_hvgs = hvgs_dict[sample1] & hvgs_dict[sample2]  # 求交集\n",
    "    print(f\"Shared HVGs between {sample1} and {sample2}: {len(shared_hvgs)}\")\n",
    "    return shared_hvgs\n",
    "\n",
    "# Step 3: 计算三个样本的共有 HVGs 数量\n",
    "def calculate_all_shared_hvgs(hvgs_dict):\n",
    "    # 计算三个集合的交集（三个样本的共有 HVGs）\n",
    "    shared_hvgs_all = hvgs_dict[\"R-MG\"] & hvgs_dict[\"S-MG\"] & hvgs_dict[\"M-MG\"]\n",
    "    print(f\"Shared HVGs across all samples: {len(shared_hvgs_all)}\")\n",
    "    return shared_hvgs_all\n",
    "\n",
    "# Step 4: Venn 图可视化\n",
    "def plot_venn(hvgs_dict, sample_names):\n",
    "    # 使用 venn 绘制 3 集合的 Venn 图\n",
    "    venn(hvgs_dict)\n",
    "    plt.title(\"Venn Diagram of different species MG HVGs\")\n",
    "    plt.savefig(\"./3-MG-venn.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(\"./3-MG-venn.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: 绘制柱状图展示不同交集的共有 HVGs 数量\n",
    "def plot_bar_chart(shared_hvgs_dict):\n",
    "    # shared_hvgs_dict 是一个字典，包含不同交集的 HVGs 数量\n",
    "    categories = list(shared_hvgs_dict.keys())\n",
    "    values = list(shared_hvgs_dict.values())\n",
    "\n",
    "    # 绘制柱状图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = ['#ff6666', '#6699cc', '#66cc66']  # 使用深色彩色柱状\n",
    "    plt.bar(categories, values, color=colors, width=0.4)  # 设置柱宽\n",
    "    plt.xlabel(\"Sample Groups\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Shared HVGs\", fontsize=12)\n",
    "    plt.title(\"Shared HVGs Across Different Speices MG\", fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./3-MG-barplot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Step 6: 保存交集结果到 CSV\n",
    "def save_shared_hvgs_to_csv(shared_hvgs_dict, hvgs_dict):\n",
    "    all_shared_hvgs = {}\n",
    "    for key, value in shared_hvgs_dict.items():\n",
    "        if key == \"R-MG & S-MG\":\n",
    "            all_shared_hvgs[key] = calculate_shared_hvgs(hvgs_dict, \"R-MG\", \"S-MG\")\n",
    "        elif key == \"R-MG & M-MG\":\n",
    "            all_shared_hvgs[key] = calculate_shared_hvgs(hvgs_dict, \"R-MG\", \"M-MG\")\n",
    "        elif key == \"S-MG & M-MG\":\n",
    "            all_shared_hvgs[key] = calculate_shared_hvgs(hvgs_dict, \"S-MG\", \"M-MG\")\n",
    "        elif key == \"All Samples (R-MG, S-MG, M-MG)\":\n",
    "            all_shared_hvgs[key] = calculate_all_shared_hvgs(hvgs_dict)\n",
    "\n",
    "    # 保存到 CSV\n",
    "    with open(\"shared_hvgs_MG.csv\", \"w\") as f:\n",
    "        f.write(\"Intersection,Shared HVGs\\n\")\n",
    "        for group, hvgs in all_shared_hvgs.items():\n",
    "            for hvg in hvgs:\n",
    "                f.write(f\"{group},{hvg}\\n\")\n",
    "    print(\"Shared HVGs have been saved to shared_hvgs.csv\")\n",
    "\n",
    "# Step 7: 主函数\n",
    "def main(file_paths, sample_names):\n",
    "    # 加载 HVGs\n",
    "    hvgs_dict = load_hvgs(file_paths, sample_names)\n",
    "\n",
    "    # 打印并计算任意两组共有 HVGs 的个数\n",
    "    for i in range(len(sample_names)):\n",
    "        for j in range(i + 1, len(sample_names)):\n",
    "            calculate_shared_hvgs(hvgs_dict, sample_names[i], sample_names[j])\n",
    "\n",
    "    # 计算三个样本的共有 HVGs 数量\n",
    "    shared_hvgs_all = calculate_all_shared_hvgs(hvgs_dict)\n",
    "\n",
    "    # 打印共有 HVGs 数量\n",
    "    print(f\"\\nShared HVGs across all samples: {len(shared_hvgs_all)}\")\n",
    "\n",
    "    # 创建包含共有 HVGs 数量的字典\n",
    "    shared_hvgs_dict = {\n",
    "        \"R-MG & S-MG\": len(calculate_shared_hvgs(hvgs_dict, \"R-MG\", \"S-MG\")),\n",
    "        \"R-MG & M-MG\": len(calculate_shared_hvgs(hvgs_dict, \"R-MG\", \"M-MG\")),\n",
    "        \"S-MG & M-MG\": len(calculate_shared_hvgs(hvgs_dict, \"S-MG\", \"M-MG\")),\n",
    "        \"All MGs\": len(shared_hvgs_all)\n",
    "    }\n",
    "\n",
    "    # 绘制 Venn 图\n",
    "    plot_venn(hvgs_dict, sample_names)\n",
    "\n",
    "    # 绘制柱状图\n",
    "    plot_bar_chart(shared_hvgs_dict)\n",
    "\n",
    "    # 保存交集结果到 CSV\n",
    "    save_shared_hvgs_to_csv(shared_hvgs_dict, hvgs_dict)\n",
    "\n",
    "# 运行主函数\n",
    "main(file_paths, sample_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc9c25-f0e1-4d21-85d4-597bc1e84730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_paths = [\n",
    "    \"../../R-MG/1.subset/R-MG_cleaned.h5ad\",  # R-MG\n",
    "    \"../../R-AG/1.subset/R-AG_cleaned.h5ad\",  # R-AG\n",
    "    \"../../S-MG/1.subset/S-MG_cleaned.h5ad\",  # S-MG\n",
    "    \"../../S-AG/1.subset/S-AG_cleaned.h5ad\",  # S-AG\n",
    "    \"../../M-MG/1.subset/M-MG_cleaned.h5ad\",  # M-MG\n",
    "    \"../../R-CG/1.subset/R-CG_cleaned.h5ad\"   # R-CG\n",
    "]\n",
    "sample_names = [\"R-MG\", \"R-AG\", \"S-MG\", \"S-AG\", \"M-MG\", \"R-CG\"]\n",
    "\n",
    "\n",
    "# Step 2: 计算交集并导出为 CSV\n",
    "def calculate_and_export_intersections(hvgs_dict, sample_names, output_csv=\"pairwise_intersections.csv\"):\n",
    "    intersections = {}\n",
    "\n",
    "    # 计算两两交集\n",
    "    for sample1, sample2 in combinations(sample_names, 2):\n",
    "        intersect_set = hvgs_dict[sample1] & hvgs_dict[sample2]\n",
    "        intersection_name = f\"{sample1} & {sample2}\"\n",
    "        intersections[intersection_name] = list(intersect_set)\n",
    "\n",
    "    # 计算 M-MG, R-MG, S-MG 三交集\n",
    "    three_intersection_set = hvgs_dict[\"M-MG\"] & hvgs_dict[\"R-MG\"] & hvgs_dict[\"S-MG\"]\n",
    "    intersections[\"M-MG & R-MG & S-MG\"] = list(three_intersection_set)\n",
    "\n",
    "    # 计算六样本交集\n",
    "    six_intersection_set = set.intersection(*(hvgs_dict[sample] for sample in sample_names))\n",
    "    intersections[\"All Samples Intersection\"] = list(six_intersection_set)\n",
    "\n",
    "    # 转换为 DataFrame 并导出 CSV\n",
    "    max_length = max(len(genes) for genes in intersections.values())\n",
    "    export_data = {name: genes + [\"\"] * (max_length - len(genes)) for name, genes in intersections.items()}\n",
    "    df = pd.DataFrame(export_data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Pairwise and additional intersections saved to {output_csv}\")\n",
    "\n",
    "# 主函数\n",
    "def main(file_paths, sample_names):\n",
    "    hvgs_dict = load_hvgs(file_paths, sample_names)\n",
    "    calculate_and_export_intersections(hvgs_dict, sample_names, output_csv=\"HVGS-pairwise_intersections.csv\")\n",
    "\n",
    "# 运行主函数\n",
    "main(file_paths, sample_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382bbbb-6069-4a9c-a2ff-b3c065de038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文件路径和样本名称\n",
    "file_paths = [\n",
    "    \"../../R-MG/1.subset/R-MG_cleaned.h5ad\",  # R-MG\n",
    "    #\"../../R-AG/1.subset/R-AG_cleaned.h5ad\",  # R-AG\n",
    "    \"../../S-MG/1.subset/S-MG_cleaned.h5ad\",  # S-MG\n",
    "    #\"../../S-AG/1.subset/S-AG_cleaned.h5ad\",  # S-AG\n",
    "    \"../../M-MG/1.subset/M-MG_cleaned.h5ad\",  # M-MG\n",
    "    #\"../../R-CG/1.subset/R-CG_cleaned.h5ad\"   # R-CG\n",
    "]\n",
    "sample_names = [\"R-MG\", \"S-MG\", \"M-MG\"]\n",
    "\n",
    "# Step 2: 计算各自独有的 HVGs\n",
    "def calculate_unique_hvgs(hvgs_dict, sample_names):\n",
    "    unique_hvgs_dict = {}\n",
    "    for i, name in enumerate(sample_names):\n",
    "        # 计算独有的 HVGs\n",
    "        other_sets = [hvgs_dict[sample_names[j]] for j in range(len(sample_names)) if j != i]\n",
    "        unique_hvgs = hvgs_dict[name] - set.union(*other_sets)\n",
    "        unique_hvgs_dict[name] = unique_hvgs\n",
    "        print(f\"Unique HVGs for {name}: {len(unique_hvgs)}\")\n",
    "    return unique_hvgs_dict\n",
    "\n",
    "# Step 3: 保存独有 HVGs 到 CSV\n",
    "def save_unique_hvgs_to_csv(unique_hvgs_dict):\n",
    "    all_data = []\n",
    "    for sample, hvgs in unique_hvgs_dict.items():\n",
    "        for hvg in hvgs:\n",
    "            all_data.append([sample, hvg])\n",
    "    \n",
    "    df = pd.DataFrame(all_data, columns=[\"Sample\", \"HVG\"])\n",
    "    output_file = \"unique_hvgs_MG.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Unique HVGs have been saved to {output_file}\")\n",
    "\n",
    "# 主函数\n",
    "def main(file_paths, sample_names):\n",
    "    # 加载 HVGs\n",
    "    hvgs_dict = load_hvgs(file_paths, sample_names)\n",
    "    \n",
    "    # 计算各自独有的 HVGs\n",
    "    unique_hvgs_dict = calculate_unique_hvgs(hvgs_dict, sample_names)\n",
    "    \n",
    "    # 保存独有 HVGs 到 CSV\n",
    "    save_unique_hvgs_to_csv(unique_hvgs_dict)\n",
    "\n",
    "# 运行主函数\n",
    "main(file_paths, sample_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340a17a-659e-4dc5-b902-52cd8f324b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 文件路径设置\n",
    "novel_gene_file = \"/data02/sunxuebo/project/scrnaseq/no-mammal/mammalnewgene/mammalian_new_genes_final.csv\"  # 包含新基因的 CSV\n",
    "intersections_file = \"HVGS-pairwise_intersections.csv\"\n",
    "output_csv = \"HVGs_novel_gene_intersections.csv\"\n",
    "\n",
    "# Step 1: 读取新基因 CSV，并提取 Novel_Gene 列构成集合\n",
    "novel_df = pd.read_csv(novel_gene_file)\n",
    "# 过滤空值并转换为字符串，构成新基因集合\n",
    "novel_genes = set(novel_df[\"mouse\"].dropna().astype(str).tolist())\n",
    "print(f\"Total novel genes found: {len(novel_genes)}\")\n",
    "\n",
    "# Step 2: 读取交集 CSV\n",
    "intersections_df = pd.read_csv(intersections_file)\n",
    "print(f\"Intersections CSV columns: {list(intersections_df.columns)}\")\n",
    "\n",
    "# Step 3: 针对每个交集类型，筛选出属于新基因的基因\n",
    "novel_intersections = {}\n",
    "for col in intersections_df.columns:\n",
    "    # 取出该列数据，去除空值和空字符串\n",
    "    genes = intersections_df[col].dropna().astype(str).tolist()\n",
    "    genes = [g.strip() for g in genes if g.strip() != \"\"]\n",
    "    # 筛选出新基因\n",
    "    novel_inters = [g for g in genes if g in novel_genes]\n",
    "    novel_intersections[col] = novel_inters\n",
    "    print(f\"Intersection '{col}': {len(novel_inters)} novel genes\")\n",
    "\n",
    "# Step 4: 找出所有交集类型中最长的列表长度，以便对齐格式\n",
    "max_length = max(len(lst) for lst in novel_intersections.values())\n",
    "\n",
    "# Step 5: 创建新 DataFrame，各列不足部分用空字符串填充\n",
    "export_data = {}\n",
    "for col, gene_list in novel_intersections.items():\n",
    "    padded_list = gene_list + [\"\"] * (max_length - len(gene_list))\n",
    "    export_data[col] = padded_list\n",
    "\n",
    "export_df = pd.DataFrame(export_data)\n",
    "\n",
    "# Step 6: 导出 CSV\n",
    "export_df.to_csv(output_csv, index=False)\n",
    "print(f\"Novel gene intersections saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0077cbd-4963-4e64-8801-75283d2485f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 Scanpy",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
